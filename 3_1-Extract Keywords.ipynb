{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3-Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "import gensim         # Gensim library for word embedding \n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk           # Natural Language Toolkit for text processing\n",
    "from nltk.corpus import stopwords        # for stopwords\n",
    "from nltk.stem import WordNetLemmatizer  # for lemmatization\n",
    "from nltk.tokenize import TweetTokenizer # TfidfVectorizer for extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV file\n",
    "df = pd.read_csv('master_covid19_2020_03_15-31 - master_covid19_2020_03_15-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>media</th>\n",
       "      <th>urls</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name.1</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_time_zone</th>\n",
       "      <th>user_urls</th>\n",
       "      <th>user_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Apr 01 00:09:33 +0000 2020</td>\n",
       "      <td>COVID„Éº19</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/124...</td>\n",
       "      <td>http://CoronaVirus.gov</td>\n",
       "      <td>0</td>\n",
       "      <td>1.245141e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cindi Puncerelli</td>\n",
       "      <td>CindiPuncerelli</td>\n",
       "      <td>172035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Mar 18 00:24:47 +0000 2020</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.240072e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2287</td>\n",
       "      <td>4996</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rosa De Ayguavives</td>\n",
       "      <td>alcanar65</td>\n",
       "      <td>40200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 31 20:25:43 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.245085e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>996</td>\n",
       "      <td>1001</td>\n",
       "      <td>30</td>\n",
       "      <td>Macap√°, Brasil</td>\n",
       "      <td>VOTE NULO/BRANCO üè¥‚Äç‚ò†Ô∏è‚ô†</td>\n",
       "      <td>G_de_Almeida</td>\n",
       "      <td>292244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Mar 18 03:32:56 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.240119e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>317</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ninda</td>\n",
       "      <td>nindamarz</td>\n",
       "      <td>1542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 17 20:18:59 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.240010e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4290</td>\n",
       "      <td>3081</td>\n",
       "      <td>0</td>\n",
       "      <td>706 üìç</td>\n",
       "      <td>11/01 ‚ôèÔ∏èü•≥ SCORPI-HOE</td>\n",
       "      <td>kpetuniaa</td>\n",
       "      <td>27823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  coordinates                      created_at     hashtags  \\\n",
       "0         NaN  Wed Apr 01 00:09:33 +0000 2020     COVID„Éº19   \n",
       "1         NaN  Wed Mar 18 00:24:47 +0000 2020  coronavirus   \n",
       "2         NaN  Tue Mar 31 20:25:43 +0000 2020          NaN   \n",
       "3         NaN  Wed Mar 18 03:32:56 +0000 2020          NaN   \n",
       "4         NaN  Tue Mar 17 20:18:59 +0000 2020          NaN   \n",
       "\n",
       "                                               media                    urls  \\\n",
       "0  https://twitter.com/realDonaldTrump/status/124...  http://CoronaVirus.gov   \n",
       "1                                                NaN                     NaN   \n",
       "2                                                NaN                     NaN   \n",
       "3                                                NaN                     NaN   \n",
       "4                                                NaN                     NaN   \n",
       "\n",
       "   favorite_count            id in_reply_to_screen_name  \\\n",
       "0               0  1.245141e+18                     NaN   \n",
       "1               0  1.240072e+18                     NaN   \n",
       "2               0  1.245085e+18                     NaN   \n",
       "3               0  1.240119e+18                     NaN   \n",
       "4               0  1.240010e+18                     NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id  ... user_followers_count  \\\n",
       "0                    NaN                  NaN  ...                  922   \n",
       "1                    NaN                  NaN  ...                 2287   \n",
       "2                    NaN                  NaN  ...                  996   \n",
       "3                    NaN                  NaN  ...                  317   \n",
       "4                    NaN                  NaN  ...                 4290   \n",
       "\n",
       "  user_friends_count user_listed_count   user_location  \\\n",
       "0                922                 0             NaN   \n",
       "1               4996                 0             NaN   \n",
       "2               1001                30  Macap√°, Brasil   \n",
       "3                601                 0             NaN   \n",
       "4               3081                 0           706 üìç   \n",
       "\n",
       "                user_name user_screen_name.1 user_statuses_count  \\\n",
       "0        Cindi Puncerelli    CindiPuncerelli              172035   \n",
       "1      Rosa De Ayguavives          alcanar65               40200   \n",
       "2  VOTE NULO/BRANCO üè¥‚Äç‚ò†Ô∏è‚ô†       G_de_Almeida              292244   \n",
       "3                   Ninda          nindamarz                1542   \n",
       "4    11/01 ‚ôèÔ∏èü•≥ SCORPI-HOE          kpetuniaa               27823   \n",
       "\n",
       "  user_time_zone user_urls user_verified  \n",
       "0            NaN       NaN         False  \n",
       "1            NaN       NaN         False  \n",
       "2            NaN       NaN         False  \n",
       "3            NaN       NaN         False  \n",
       "4            NaN       NaN         False  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['coordinates', 'created_at', 'hashtags', 'media', 'urls',\n",
       "       'favorite_count', 'id', 'in_reply_to_screen_name',\n",
       "       'in_reply_to_status_id', 'in_reply_to_user_id', 'lang', 'place',\n",
       "       'possibly_sensitive', 'retweet_count', 'retweet_id',\n",
       "       'retweet_screen_name', 'source', 'text', 'tweet_url', 'user_created_at',\n",
       "       'user_screen_name', 'user_default_profile_image', 'user_description',\n",
       "       'user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
       "       'user_listed_count', 'user_location', 'user_name', 'user_screen_name.1',\n",
       "       'user_statuses_count', 'user_time_zone', 'user_urls', 'user_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24351, 34)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24351 entries, 0 to 24350\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   coordinates                 8 non-null      object \n",
      " 1   created_at                  24351 non-null  object \n",
      " 2   hashtags                    10062 non-null  object \n",
      " 3   media                       2892 non-null   object \n",
      " 4   urls                        5402 non-null   object \n",
      " 5   favorite_count              24351 non-null  int64  \n",
      " 6   id                          24351 non-null  float64\n",
      " 7   in_reply_to_screen_name     1186 non-null   object \n",
      " 8   in_reply_to_status_id       1057 non-null   float64\n",
      " 9   in_reply_to_user_id         1186 non-null   float64\n",
      " 10  lang                        24351 non-null  object \n",
      " 11  place                       200 non-null    object \n",
      " 12  possibly_sensitive          7475 non-null   object \n",
      " 13  retweet_count               24351 non-null  int64  \n",
      " 14  retweet_id                  18424 non-null  float64\n",
      " 15  retweet_screen_name         18424 non-null  object \n",
      " 16  source                      24351 non-null  object \n",
      " 17  text                        24351 non-null  object \n",
      " 18  tweet_url                   24351 non-null  object \n",
      " 19  user_created_at             24351 non-null  object \n",
      " 20  user_screen_name            24351 non-null  object \n",
      " 21  user_default_profile_image  24351 non-null  bool   \n",
      " 22  user_description            20071 non-null  object \n",
      " 23  user_favourites_count       24351 non-null  int64  \n",
      " 24  user_followers_count        24351 non-null  int64  \n",
      " 25  user_friends_count          24351 non-null  int64  \n",
      " 26  user_listed_count           24351 non-null  int64  \n",
      " 27  user_location               16646 non-null  object \n",
      " 28  user_name                   24350 non-null  object \n",
      " 29  user_screen_name.1          24351 non-null  object \n",
      " 30  user_statuses_count         24351 non-null  int64  \n",
      " 31  user_time_zone              0 non-null      float64\n",
      " 32  user_urls                   6577 non-null   object \n",
      " 33  user_verified               24351 non-null  bool   \n",
      "dtypes: bool(2), float64(5), int64(7), object(20)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) How many languages are available in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_languages = len(df['lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of languages in the dataset: 46\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of languages in the dataset:\", num_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) How many messages per each language in the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_counts = df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en     14849\n",
       "es      5538\n",
       "fr      1193\n",
       "pt       493\n",
       "in       402\n",
       "it       339\n",
       "und      245\n",
       "th       229\n",
       "ca       213\n",
       "tr       140\n",
       "hi       139\n",
       "de       135\n",
       "tl        71\n",
       "ja        62\n",
       "nl        56\n",
       "ar        33\n",
       "lt        28\n",
       "pl        23\n",
       "ta        20\n",
       "ru        17\n",
       "ro        14\n",
       "ko        11\n",
       "te        11\n",
       "ur        10\n",
       "fi        10\n",
       "zh         9\n",
       "mr         9\n",
       "da         6\n",
       "sr         5\n",
       "sv         5\n",
       "ht         5\n",
       "el         4\n",
       "cs         4\n",
       "et         4\n",
       "ml         4\n",
       "kn         2\n",
       "bn         2\n",
       "sl         2\n",
       "fa         2\n",
       "ne         1\n",
       "si         1\n",
       "gu         1\n",
       "eu         1\n",
       "lv         1\n",
       "no         1\n",
       "is         1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14849 messages in en(English), 5538 messages in es(Spanish), 1193 messages in fr(Franch), 493 messages in pt(Portuguese) and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) What are the top 5 most frequent hashtags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_counts = df['hashtags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COVID19        2178\n",
       "coronavirus    1195\n",
       "Coronavirus     446\n",
       "Covid19         228\n",
       "COVID„Éº19        195\n",
       "Name: hashtags, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_counts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 most frequent hashtags are \"COVID19\",\"coronavirus\",\"Coronavirus\",\"Covid19\",\"COVID„Éº19\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Select the messages (i.e., the text field) of the langauge with the largest number of messages. Tokenize the messages in the \"text\" field using an appropriate tokenizer and extract the top 5 keywords using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @realDonaldTrump: 30 DAYS TO SLOW THE SPREA...\n",
       "2    RT @spectatorindex: JUST IN: 13 year old who t...\n",
       "4    RT @StephMcNasty: The Coronavirus is really sh...\n",
       "6    RT @CharlieDaniels: Hazel and myself send our ...\n",
       "7    RT @PrakritiGaba: Last night in the ICU of a #...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only the English tweets\n",
    "\n",
    "df_en = df.loc[df['lang'] == 'en']['text']\n",
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the texts in the 'df_en' DataFrame into a single string\n",
    "all_texts = ' '.join(df_en.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing code retrived from: https://gist.github.com/MrEliptik/b3f16179aa2f530781ef8ca9a16499af\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "     # Remove word \"RT\" \n",
    "    text = re.sub(r'\\bRT\\b', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords and lemmatize tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    # Rejoin tokens into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "all_texts = preprocess_text(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        000     00005       001       002       005       007        01  \\\n",
      "0  0.000332  0.000083  0.000083  0.000083  0.000083  0.000083  0.000166   \n",
      "\n",
      "   012481398     01253       014  ...       ùíïùíâùíÜ      ùóïùóùùó£ùòÄ  ùóôùó≤ùóØùóøùòÇùóÆùóøùòÜ   ùóùùóÆùóªùòÇùóÆùóøùòÜ  \\\n",
      "0   0.000083  0.000083  0.000083  ...  0.000249  0.000083  0.000083  0.000083   \n",
      "\n",
      "       ùóûùó≤ùó≤ùóΩ     ùó†ùóÆùóøùó∞ùóµ  ùóπùó≤ùóÆùóøùóªùó∂ùóªùó¥  ùóøùó≤ùòÄùóΩùóºùóªùòÄùó≤        ùòÅùóº        ùü≠ùü≥  \n",
      "0  0.000083  0.000083  0.000083  0.000083  0.000083  0.000083  \n",
      "\n",
      "[1 rows x 26929 columns]\n"
     ]
    }
   ],
   "source": [
    "# stop words in English\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# compute the TF-IDF values for the texts\n",
    "texts_tfidf = tfidf_vectorizer.fit_transform([all_texts])\n",
    "\n",
    "# create a DataFrame from the TF-IDF matrix and feature names\n",
    "texts_tfidf_matrix = pd.DataFrame(texts_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(texts_tfidf_matrix)\n",
    "\n",
    "# convert the TF-IDF DataFrame into a dictionary\n",
    "words_dict_tfidf = texts_tfidf_matrix.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('coronavirus', 0.8796961555697431), ('covid19', 0.2736592553438731), ('case', 0.10489579347475317), ('covid', 0.10173978385318498), ('trump', 0.09650745211216404)]\n"
     ]
    }
   ],
   "source": [
    "# create an empty dictionary to store the words and TF-IDF score\n",
    "# iterate over each text and its TF-IDF dictionary\n",
    "\n",
    "words_tfidf = {}\n",
    "for text_id, target_words in words_dict_tfidf.items():\n",
    "    list_targets = [(k, v) for k, v in target_words.items()]\n",
    "    list_targets_sorted = sorted(list_targets, key=lambda x: x[1], reverse=True)\n",
    "    words_tfidf = list_targets_sorted[0:5]\n",
    "\n",
    "print(words_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>0.879696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid19</td>\n",
       "      <td>0.273659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case</td>\n",
       "      <td>0.104896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>0.101740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump</td>\n",
       "      <td>0.096507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     tfidf\n",
       "0  coronavirus  0.879696\n",
       "1      covid19  0.273659\n",
       "2         case  0.104896\n",
       "3        covid  0.101740\n",
       "4        trump  0.096507"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top = pd.DataFrame(words_tfidf, columns=['word', 'tfidf'])\n",
    "df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 words are: \"coronavirus\", \"covid19\", \"case\", \"covid\" and \"trump\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
